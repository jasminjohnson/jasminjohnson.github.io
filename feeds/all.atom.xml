<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Financial Analysis Journal</title><link href="http://jasminjohnson.github.io/" rel="alternate"></link><link href="http://jasminjohnson.github.io/feeds/all.atom.xml" rel="self"></link><id>http://jasminjohnson.github.io/</id><updated>2018-04-16T10:00:00-04:00</updated><entry><title>Using Pandas for Stock Analysis</title><link href="http://jasminjohnson.github.io/blog/2018/04/16/using-pandas-for-stock-analysis/" rel="alternate"></link><published>2018-04-16T10:00:00-04:00</published><updated>2018-04-16T10:00:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2018-04-16:blog/2018/04/16/using-pandas-for-stock-analysis/</id><summary type="html">&lt;style type="text/css"&gt;/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the …&lt;/style&gt;</summary><category term="stock"></category><category term="pandas"></category></entry><entry><title>Simulating Chutes &amp; Ladders in Python</title><link href="http://jasminjohnson.github.io/blog/2017/12/18/simulating-chutes-and-ladders/" rel="alternate"></link><published>2017-12-18T10:00:00-05:00</published><updated>2017-12-18T10:00:00-05:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2017-12-18:blog/2017/12/18/simulating-chutes-and-ladders/</id><summary type="html">

&lt;p&gt;&lt;img src="http://jakevdp.github.io/images/ChutesAndLadders-sim.gif" alt='[img: Chutes and Ladders animated simulation]'&gt;&lt;/p&gt;
&lt;p&gt;This weekend I found myself in a particularly drawn-out game of Chutes and Ladders with my four-year-old. If you've not had the pleasure of playing it, Chutes and Ladders (also sometimes known as &lt;a href="https://en.wikipedia.org/wiki/Snakes_and_Ladders"&gt;Snakes and Ladders&lt;/a&gt;) is a classic kids board game wherein players roll a six-sided die to advance forward through 100 squares, using "ladders" to jump ahead, and avoiding "chutes" that send you backward. It's basically a glorified random walk with visual aids to help you build a narrative. Thrilling. But she's having fun practicing counting, learning to win and lose gracefully, and developing the requisite skills to be a &lt;a href="https://xkcd.com/904/"&gt;passionate sports fan&lt;/a&gt;, so I play along.&lt;/p&gt;
&lt;p&gt;On the approximately twenty third game of the morning, as we found ourselves in a near endless cycle of climbing ladders and sliding down chutes, never quite reaching that final square to end the game, I started wondering how much longer the game could last: what is the expected length of a game? How heavy are the tails of the game length distribution? How succinctly could I answer those questions in Python? And then, at some point, it &lt;a href="https://twitter.com/jakevdp/status/942456865580924928"&gt;clicked&lt;/a&gt;: Chutes and Ladders is memoryless — the effect of a roll depends only on where you are, not where you've been — and so it can be modeled as a Markov process! By the time we (finally) hit square 100, I basically had this blog post written, at least in my head.&lt;/p&gt;
&lt;p&gt;When I &lt;a href="https://twitter.com/jakevdp/status/942456865580924928"&gt;tweeted about this&lt;/a&gt;, people pointed me to a &lt;a href="http://www.datagenetics.com/blog/november12011/"&gt;number&lt;/a&gt; of &lt;a href="https://gist.github.com/CamDavidsonPilon/1639d06c448904afaf7b7449910f3b72"&gt;similar&lt;/a&gt; &lt;a href="https://math.byu.edu/~jeffh/mathematics/games/chutes/chutes.html"&gt;treatments&lt;/a&gt; of &lt;a href="https://roycoding.github.io/chutes-ladders-d3/"&gt;Chutes&lt;/a&gt; &amp;amp; &lt;a href="https://scipython.com/book/chapter-6-numpy/additional-problems/analysing-snakes-and-ladders-as-a-markov-chain/"&gt;Ladders&lt;/a&gt;, so I'm under no illusion that this idea is original.
Think of this as a blog post version of a dad joke: my primary goal is not originality, but self-entertainment, and if anyone else finds it entertaining that's just an added bonus.&lt;/p&gt;
</summary><category term="simulation"></category><category term="animation"></category></entry><entry><title>A Practical Guide to the Lomb-Scargle Periodogram</title><link href="http://jasminjohnson.github.io/blog/2017/03/30/practical-lomb-scargle/" rel="alternate"></link><published>2017-03-30T06:00:00-04:00</published><updated>2017-03-30T06:00:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2017-03-30:blog/2017/03/30/practical-lomb-scargle/</id><summary type="html">

&lt;p&gt;This week I published the preprint of a manuscript that started as a blog post, but quickly out-grew this medium: &lt;a href="http://arxiv.org/abs/1703.09824"&gt;Understanding the Lomb-Scargle Periodogram&lt;/a&gt;.&lt;/p&gt;
&lt;table class="image"&gt;
&lt;caption align="bottom" style="padding-left: 20px; padding-right:20px; font-size:small"&gt;Figure 24 from &lt;a href="http://arxiv.org/abs/1703.09824"&gt;Understanding the Lomb-Scargle Periodogram&lt;/a&gt;. The figure shows the true period vs the periodogram peak for a
simulated dataset with an observing cadence typical of ground-based optical astronomy.
The simulation reveals common patterns of failure of the Lomb-Scargle method that are not
often discussed explicitly, but are straightforward to explain based on the intuition
developed in the paper; see Section 7.2 for a detailed discussion.&lt;/caption&gt;
&lt;tr&gt;&lt;td&gt;&lt;img src="/figures/lomb-scargle-failure-modes.png" alt="failure modes"/&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Over the last couple years I've written a number of Python implementations of the Lomb-Scargle periodogram (I'd recommend &lt;a href="http://docs.astropy.org/en/stable/stats/lombscargle.html"&gt;AstroPy's &lt;code&gt;LombScargle&lt;/code&gt;&lt;/a&gt; in most cases today), and also wrote a &lt;a href="/blog/2015/06/13/lomb-scargle-in-python/"&gt;marginally popular blog post&lt;/a&gt; and &lt;a href="https://arxiv.org/abs/1502.01344"&gt;somewhat pedagogical paper&lt;/a&gt; on the subject.
This all has led to a steady trickle of emails from students and researchers asking for advice on applying and interpreting the Lomb-Scargle algorithm, particularly for astronomical data.
I noticed that these queries tended to repeat many of the same questions and express some similar misconceptions, and this paper is my attempt to address those once and for all — in a "mere" 55 pages (which includes 26 figures and 4 full pages of references, so it's not all that bad).&lt;/p&gt;
</summary><category term="lomb-scargle"></category></entry><entry><title>On Frequentism and Fried Chicken</title><link href="http://jasminjohnson.github.io/blog/2014/09/02/on-frequentism-and-fried-chicken/" rel="alternate"></link><published>2014-09-02T16:00:00-04:00</published><updated>2014-09-02T16:00:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2014-09-02:blog/2014/09/02/on-frequentism-and-fried-chicken/</id><summary type="html">

&lt;p&gt;My recent series of posts on &lt;a href="http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/"&gt;Frequentism and Bayesianism&lt;/a&gt; have drawn a lot of comments, but recently Frederick J. Ross, a UW colleague whom I have not yet had the pleasure of meeting, penned a particularly strong-worded critique: &lt;a href="http://madhadron.com/posts/2014-08-30-frequentist_and_bayesian_statistics.html"&gt;Bayesian vs frequentist: squabbling among the ignorant&lt;/a&gt;. Here I want to briefly explore and respond to the points he makes in the post.
</summary><category term="frequentism"></category><category term="bayesianism"></category></entry><entry><title>Hacking Academia: Data Science and the University</title><link href="http://jasminjohnson.github.io/blog/2014/08/22/hacking-academia/" rel="alternate"></link><published>2014-08-22T08:00:00-04:00</published><updated>2014-08-22T08:00:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2014-08-22:blog/2014/08/22/hacking-academia/</id><summary type="html">

&lt;p&gt;&lt;em&gt;A reflection on our &lt;a href="http://www.digital-science.com/sciencefoo/"&gt;SciFoo&lt;/a&gt; breakout session, where we discussed issues of data science within academia.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Almost a year ago, I wrote a post I called the &lt;a href="http://jakevdp.github.io/blog/2013/10/26/big-data-brain-drain/"&gt;Big Data Brain Drain&lt;/a&gt;, lamenting the ways that academia is neglecting the skills of modern data-intensive research, and in doing so is driving away many of the men and women who are perhaps best equipped to enable progress in these fields. This seemed to strike a chord with a wide range of people, and has led me to some incredible opportunities for conversation and collaboration on the subject. One of those conversations took place at the recent SciFoo conference, and this article is my way of recording some reflections on that conversation.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.digital-science.com/sciencefoo/"&gt;SciFoo&lt;/a&gt; is an annual gathering of several hundred scientists, writers, and thinkers sponsored by Digital Science, Nature, O'Reilly Media &amp;amp; Google. SciFoo brings together an incredibly eclectic group of people: I met philosophers, futurists, alien hunters, quantum physicists, mammoth cloners, magazine editors, science funders, astrophysicists, musicians, mycologists, mesmerists, and many many more: the list could go on and on. The conference is about as unstructured as it can be: the organizers simply provide food, drink, and a venue for conversation, and attendees put together breakout discussions on nearly any imaginable topic. If you ever get the chance to go, my advice is to drop everything else and attend. It was one of the most quirky and intellectually stimulating weekends I've ever spent.&lt;/p&gt;
</summary><category term="opinion"></category><category term="academia"></category></entry><entry><title>The Big Data Brain Drain: Why Science is in Trouble</title><link href="http://jasminjohnson.github.io/blog/2013/10/26/big-data-brain-drain/" rel="alternate"></link><published>2013-10-26T13:00:00-04:00</published><updated>2013-10-26T13:00:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2013-10-26:blog/2013/10/26/big-data-brain-drain/</id><summary type="html">

&lt;p&gt;Regardless of what you might think of the ubiquity of the "Big Data" meme, it's clear that the growing size of datasets is changing the way we approach the world around us.  This is true in fields from industry to government to media to academia and virtually everywhere in between. Our increasing abilities to gather, process, visualize, and learn from large datasets is helping to push the boundaries of our knowledge.&lt;/p&gt;
&lt;p&gt;But where scientific research is concerned, this recently accelerated shift to data-centric science has a dark side, which boils down to this: &lt;strong&gt;the skills required to be a successful scientific researcher are increasingly indistinguishable from the skills required to be successful in industry.&lt;/strong&gt; While academia, with typical inertia, gradually shifts to accommodate this, the rest of the world has already begun to embrace and reward these skills to a much greater degree. &lt;em&gt;The unfortunate result is that some of the most promising upcoming researchers are finding no place for themselves in the academic community, while the for-profit world of industry stands by with deep pockets and open arms.&lt;/em&gt;
</summary><category term="academia"></category><category term="opinion"></category></entry><entry><title>Matplotlib and the Future of Visualization in Python</title><link href="http://jasminjohnson.github.io/blog/2013/03/23/matplotlib-and-the-future-of-visualization-in-python/" rel="alternate"></link><published>2013-03-23T08:31:00-04:00</published><updated>2013-03-23T08:31:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2013-03-23:blog/2013/03/23/matplotlib-and-the-future-of-visualization-in-python/</id><summary type="html">

&lt;p&gt;Last week, I had the privilege of attending and speaking at the
PyCon and PyData conferences in Santa Clara, CA.  As usual, there were some
amazing and inspiring talks throughout: I would highly recommend browsing
through the videos as they are put up on
&lt;a href="http://pyvideo.org/category/33/pycon-us-2013"&gt;pyvideo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One thing I spent a lot of time thinking, talking, and learning about
during these two conferences was the topic of data visualization in Python.
Data visualization seemed to be everywhere: PyData had
&lt;a href="http://sv2013.pydata.org/abstracts/#11"&gt;two&lt;/a&gt;
&lt;a href="http://sv2013.pydata.org/abstracts/#15"&gt;tutorials&lt;/a&gt;
on matplotlib (the second given by yours truly), as well as a talk about
&lt;a href="http://sv2013.pydata.org/abstracts/#41"&gt;NodeBox OpenGL&lt;/a&gt; and a
&lt;a href="http://sv2013.pydata.org/keynotes/#abstract_33"&gt;keynote&lt;/a&gt; by
Fernando Perez about IPython, including the notebook and the
nice interactive data-visualization it allows. Pycon had a tutorial on
&lt;a href="https://us.pycon.org/2013/schedule/presentation/29/"&gt;network visualization&lt;/a&gt;,
a talk on &lt;a href="https://us.pycon.org/2013/schedule/presentation/58/"&gt;generating art&lt;/a&gt;
in Python, and a talk on
&lt;a href="https://us.pycon.org/2013/schedule/presentation/108/"&gt;visualizing Github&lt;/a&gt;. &lt;/p&gt;
</summary><category term="matplotlib"></category><category term="opinion"></category></entry><entry><title>Animating the Lorenz System in 3D</title><link href="http://jasminjohnson.github.io/blog/2013/02/16/animating-the-lorentz-system-in-3d/" rel="alternate"></link><published>2013-02-16T08:05:00-05:00</published><updated>2013-02-16T08:05:00-05:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2013-02-16:blog/2013/02/16/animating-the-lorentz-system-in-3d/</id><summary type="html">

&lt;p&gt;One of the things I really enjoy about Python is how easy it makes it to solve
interesting problems and visualize those solutions in a compelling way. I've
done several posts on creating animations using matplotlib's relatively new
&lt;a href="http://matplotlib.sourceforge.net/api/animation_api.html"&gt;animation toolkit&lt;/a&gt;:
(some examples are a chaotic
&lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial/"&gt;double pendulum&lt;/a&gt;,
the collisions of
&lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial/"&gt;particles in a box&lt;/a&gt;,
the time-evolution of a
&lt;a href="/blog/2012/09/05/quantum-python/"&gt;quantum-mechanical wavefunction&lt;/a&gt;,
and even a scene from the classic video game,
&lt;a href="/blog/2013/01/13/hacking-super-mario-bros-with-python/"&gt;Super Mario Bros.&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Recently, a reader &lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial/#comment-799781196"&gt;commented&lt;/a&gt; asking whether I might do a 3D animation example.  Matplotlib
has a decent 3D toolkit called
&lt;a href="http://matplotlib.org/mpl_toolkits/mplot3d/index.html"&gt;mplot3D&lt;/a&gt;,
and though I haven't previously seen it used in conjunction with the
animation tools, there's nothing fundamental that prevents it.&lt;/p&gt;
&lt;p&gt;At the commenter's suggestion, I decided to try this out with a simple
example of a chaotic system: the Lorenz equations.&lt;/p&gt;
</summary><category term="matplotlib"></category><category term="animation"></category><category term="tutorial"></category></entry><entry><title>Setting Up a Mac for Python Development</title><link href="http://jasminjohnson.github.io/blog/2013/02/02/setting-up-a-mac-for-python-development/" rel="alternate"></link><published>2013-02-02T11:01:00-05:00</published><updated>2013-02-02T11:01:00-05:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2013-02-02:blog/2013/02/02/setting-up-a-mac-for-python-development/</id><summary type="html">

&lt;p&gt;&lt;em&gt;Edit, August 2013: my current favorite way to set up a python installation
on mac (and any other system) is to use the
&lt;a href="https://store.continuum.io/"&gt;anaconda&lt;/a&gt; package offered by Continuum
Analytics.  It's free, full-featured, and extremely easy to use.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class="left" src="/images/OSX10.8.png" title="'OSX 10.8 Logo'" alt="'OSX 10.8 Logo'"&gt; A few weeks ago,
after years of using Linux exclusively for all my computing,
I started a research fellowship in a new department
and found a brand new Macbook Pro on my
desk.  Naturally, my first instinct was to set up the system for efficient
Python development.  In order to help others who  might find themself in a
similar situation, I took some notes on the process, and I'll summarize
what I learned below.&lt;/p&gt;
</summary><category term="osx"></category><category term="development"></category></entry><entry><title>Hacking Super Mario Bros. with Python</title><link href="http://jasminjohnson.github.io/blog/2013/01/13/hacking-super-mario-bros-with-python/" rel="alternate"></link><published>2013-01-13T10:32:00-05:00</published><updated>2013-01-13T10:32:00-05:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2013-01-13:blog/2013/01/13/hacking-super-mario-bros-with-python/</id><summary type="html">

&lt;p&gt;This weekend I was coming home from the meeting of the
&lt;a href="http://www.lsst.org"&gt;LSST&lt;/a&gt; Dark Energy Science Collaboration,
and found myself with a few extra hours in the airport.
I started passing the time by poking around on the &lt;a href="http://imgur.com"&gt;imgur&lt;/a&gt;
gallery, and saw a couple animated gifs based on
one of my all-time favorite games, Super Mario Bros.
It got me wondering: could I use matplotlib's animation tools to create these
sorts of gifs in Python?  Over a few beers at an SFO bar, I started to try
to figure it out.  To spoil the punchline a bit, I managed to do it, and the
result looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img class="center" src="/images/mario.gif"&gt;&lt;/p&gt;
&lt;p&gt;This animation was created &lt;em&gt;entirely in Python and matplotlib&lt;/em&gt;, by scraping the
image data directly from the Super Mario Bros. ROM.  Below I'll explain how
I managed to do it.&lt;/p&gt;
</summary><category term="matplotlib"></category><category term="animation"></category><category term="nintendo"></category></entry><entry><title>Will Scientists Ever Move to Python 3?</title><link href="http://jasminjohnson.github.io/blog/2013/01/03/will-scientists-ever-move-to-python-3/" rel="alternate"></link><published>2013-01-03T17:08:00-05:00</published><updated>2013-01-03T17:08:00-05:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2013-01-03:blog/2013/01/03/will-scientists-ever-move-to-python-3/</id><summary type="html">

&lt;p&gt;&lt;em&gt;March 2016: Please note the date on this post. Given the developments in the last three years, I would no longer agree with much of what I've written here. In particular, I substantially underestimated the ability of tools like &lt;a href="http://pythonhosted.org/six/"&gt;six&lt;/a&gt; and &lt;a href="http://python-future.org/"&gt;python-future&lt;/a&gt; to enable single-codebase Python 2/3 support, and virtually all scientific packages now use such tools to support both. Short version: just use Python 3. There's almost no reason not to any more.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It's been just over four years since the introduction of Python 3, and there
are still about as many opinions on it as there are Python users.  For
those who haven't been following, Python 3 is a release
which offers several nice improvements over the 2.x series
(summarized &lt;a href="http://docs.python.org/3/whatsnew/3.0.html"&gt;here&lt;/a&gt;)
with the distinct disadvantage that it broke backward compatibility:
though Python 3.x (often referred to as "Py3k" for short)
is true to the spirit of earlier Python versions,
there are a few valid 2.x constructions which will not parse under 3.x.&lt;/p&gt;
&lt;p&gt;Breaking backward compatibility was controversial, to say the least.  I
think of the debate as one between the pragmatists -- those who see Python
as an extremely useful tool, which should not be unnecessarily tampered with --
and the idealists -- those who view the Python language
as a living, breathing entity, which should be allowed to grow into the
fullest and most Pythonic possible version of itself.&lt;/p&gt;
</summary><category term="academia"></category><category term="opinion"></category></entry><entry><title>Sparse SVDs in Python</title><link href="http://jasminjohnson.github.io/blog/2012/12/19/sparse-svds-in-python/" rel="alternate"></link><published>2012-12-19T08:21:00-05:00</published><updated>2012-12-19T08:21:00-05:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2012-12-19:blog/2012/12/19/sparse-svds-in-python/</id><summary type="html">

&lt;p&gt;After &lt;a href="http://fseoane.net/blog/2012/singular-value-decomposition-in-scipy/"&gt;Fabian's post&lt;/a&gt; on the topic, I have recently returned to thinking about the
subject of sparse singular value decompositions (SVDs) in Python.&lt;/p&gt;
&lt;p&gt;For those who haven't used it, the SVD is an extremely powerful technique.
It is the core routine of many applications,
from filtering to dimensionality
reduction to graph analysis to supervised classification and much, much more.&lt;/p&gt;
&lt;p&gt;I first came across the need for a fast sparse SVD when applying a technique
called Locally Linear Embedding (LLE) to astronomy spectra: it was the first
astronomy paper I published, and you can read it &lt;a href="http://adsabs.harvard.edu/abs/2009AJ....138.1365V"&gt;here&lt;/a&gt;.  In LLE, one visualizes the nonlinear relationship
between high-dimensional observations.  The computational cost is extreme: for
&lt;em&gt;N&lt;/em&gt; objects, one must compute the null space (intimately related to the SVD)
of a &lt;em&gt;N&lt;/em&gt; by &lt;em&gt;N&lt;/em&gt; matrix.  Using direct methods (e.g. LAPACK), this can scale
as bad as $\mathcal{O}[N^3]$ in both memory and speed!&lt;/p&gt;
</summary><category term="linear algebra"></category><category term="benchmarks"></category></entry><entry><title>Minesweeper in Matplotlib</title><link href="http://jasminjohnson.github.io/blog/2012/12/06/minesweeper-in-matplotlib/" rel="alternate"></link><published>2012-12-06T18:23:00-05:00</published><updated>2012-12-06T18:23:00-05:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2012-12-06:blog/2012/12/06/minesweeper-in-matplotlib/</id><summary type="html">

&lt;p&gt;Lately I've been playing around with interactivity in matplotlib.  A couple
weeks ago, I discussed briefly how to use event callbacks to implement
&lt;a href="/blog/2012/11/24/simple-3d-visualization-in-matplotlib/"&gt;simple 3D visualization&lt;/a&gt;
and later used this as a base for creating a
&lt;a href="/blog/2012/11/26/3d-interactive-rubiks-cube-in-python"&gt;working 3D Rubik's cube&lt;/a&gt;
entirely in matplotlib.&lt;/p&gt;
&lt;p&gt;Today I have a different goal: re-create
&lt;a href="http://en.wikipedia.org/wiki/Minesweeper_%28computer_game%29"&gt;minesweeper&lt;/a&gt;,
that ubiquitous single-player puzzle game that most of us will admit to
having binged on at least once or twice in their lives.  In minesweeper, the
goal is to discover and avoid hidden mines within a gridded minefield, and
the process takes some logic and quick thinking.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/minesweeper_2.gif" width="800"&gt;&lt;/p&gt;
</summary><category term="matplotlib"></category></entry><entry><title>3D Interactive Rubik's Cube in Python</title><link href="http://jasminjohnson.github.io/blog/2012/11/26/3d-interactive-rubiks-cube-in-python/" rel="alternate"></link><published>2012-11-26T22:00:00-05:00</published><updated>2012-11-26T22:00:00-05:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2012-11-26:blog/2012/11/26/3d-interactive-rubiks-cube-in-python/</id><summary type="html">

&lt;p&gt;Over the weekend, I built a interactive 3D Rubik's cube simulator in python
using only &lt;a href="http://matplotlib.org"&gt;matplotlib&lt;/a&gt; for all the graphics and
interaction.  Check out the demonstration here:&lt;/p&gt;
&lt;p&gt;&lt;span class="videobox"&gt;
            &lt;video width="680" height="400" preload="none" controls poster="/downloads/videos/MagicCube_frame.jpg"&gt;&lt;source src='/downloads/videos/MagicCube.mp4' type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'&gt;&lt;/video&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;You can browse the source code at the MagicCube github repository:
&lt;a href="http://github.com/davidwhogg/MagicCube"&gt;http://github.com/davidwhogg/MagicCube&lt;/a&gt;.&lt;/p&gt;
</summary><category term="matplotlib"></category></entry><entry><title>Optical Illusions in Matplotlib</title><link href="http://jasminjohnson.github.io/blog/2012/09/26/optical-illusions-in-matplotlib/" rel="alternate"></link><published>2012-09-26T07:27:00-04:00</published><updated>2012-09-26T07:27:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2012-09-26:blog/2012/09/26/optical-illusions-in-matplotlib/</id><summary type="html">

&lt;p&gt;A while ago I posted some information on the new matplotlib animation
package (see my tutorial
&lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial"&gt;here&lt;/a&gt; and
a followup post &lt;a href="/blog/2012/09/05/quantum-python"&gt;here&lt;/a&gt;).  In them, I show
how easy it is to  use matplotlib to create simple animations.&lt;/p&gt;
&lt;p&gt;This morning I came across this cool optical illusion on
&lt;a href="http://gizmodo.com/5945194/this-optical-trick-is-annoying-the-hell-out-of-me"&gt;gizmodo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/original_illusion.gif"&gt;&lt;/p&gt;
</summary><category term="matplotlib"></category><category term="animation"></category></entry><entry><title>Why Python is the Last Language You'll Have To Learn</title><link href="http://jasminjohnson.github.io/blog/2012/09/20/why-python-is-the-last/" rel="alternate"></link><published>2012-09-20T20:50:00-04:00</published><updated>2012-09-20T20:50:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2012-09-20:blog/2012/09/20/why-python-is-the-last/</id><summary type="html">

&lt;p&gt;This week, for part of a textbook I'm helping to write,
I spent some time reading and researching the history of Python as
a scientific computing tool.  I had heard bits and pieces of this in the past,
but it was fascinating to put it all together and learn about how all the
individual contributions that have made Python what it is today.
All of this got me thinking: for most of us, Python was a replacement for
something: IDL, MatLab, Java, Mathematica, Perl... you name it.
But what will replace Python?
Ten years down the road, what language will people be espousing in
blogs with awkwardly-alliterated titles?  As I thought it through, I
became more and more convinced that, at least in the scientific computing
world, Python is here to stay.&lt;/p&gt;
</summary><category term="opinion"></category><category term="python"></category></entry><entry><title>Dynamic Programming in Python: Bayesian Blocks</title><link href="http://jasminjohnson.github.io/blog/2012/09/12/dynamic-programming-in-python/" rel="alternate"></link><published>2012-09-12T19:02:00-04:00</published><updated>2012-09-12T19:02:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2012-09-12:blog/2012/09/12/dynamic-programming-in-python/</id><summary type="html">

&lt;p&gt;Of all the programming styles I have learned,
&lt;a href="http://en.wikipedia.org/wiki/Dynamic_programming"&gt;dynamic programming&lt;/a&gt;
is perhaps the most beautiful.  It can take problems that, at first glance,
look ugly and intractable, and solve the problem with clean, concise code.
Where a simplistic algorithm might accomplish something by brute force,
dynamic programming steps back, breaks the task into a smaller set of
sequential parts, and then proceeds in the most efficient way possible.&lt;/p&gt;
&lt;h3&gt;Bayesian Blocks&lt;/h3&gt;
&lt;p&gt;I'll go through an example here where the ideas of dynamic programming
are vital to some very cool data analysis resuts.
This post draws heavily from a recent
&lt;a href="http://adsabs.harvard.edu/abs/2012arXiv1207.5578S"&gt;paper&lt;/a&gt; by Jeff Scargle
and collaborators (this is the Scargle of &lt;em&gt;Lomb-Scargle Periodogram&lt;/em&gt;
fame), as well as some conversations I had with Jeff at
&lt;a href="http://www.astro.caltech.edu/ai12/"&gt;Astroinformatics 2012&lt;/a&gt;.
The paper discusses
a framework called &lt;em&gt;Bayesian Blocks&lt;/em&gt;, which is essentially a method of
creating histograms with bin sizes that adapt to the data (there's a bit
more to it than that: here we'll focus on histograms for simplicity).&lt;/p&gt;
</summary><category term="tutorial"></category></entry><entry><title>Quantum Python: Animating the Schrodinger Equation</title><link href="http://jasminjohnson.github.io/blog/2012/09/05/quantum-python/" rel="alternate"></link><published>2012-09-05T20:12:00-04:00</published><updated>2012-09-05T20:12:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2012-09-05:blog/2012/09/05/quantum-python/</id><summary type="html">

&lt;p&gt;&lt;em&gt;Update: a reader contributed some improvements to the Python code presented
 below.  Please see the
&lt;a href="https://github.com/jakevdp/pySchrodinger"&gt;pySchrodinger&lt;/a&gt; github repository
for updated code&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In a &lt;a href="/blog/2012/08/18/matplotlib-animation-tutorial/"&gt;previous post&lt;/a&gt;
I explored the new animation capabilities of the latest
&lt;a href="http://matplotlib.sourceforge.net"&gt;matplotlib&lt;/a&gt; release.
It got me wondering whether it would be possible to simulate more complicated
physical systems in real time in python.  Quantum Mechanics was the first
thing that came to mind.  It turns out that by mixing a bit of Physics
knowledge with a bit of computing knowledge, it's quite straightforward
to simulate and animate a simple quantum mechanical system with python.&lt;/p&gt;
&lt;h2&gt;The Schrodinger Equation&lt;/h2&gt;
&lt;p&gt;The dynamics of a one-dimensional quantum system are governed by the
time-dependent Schrodinger equation:&lt;/p&gt;
&lt;p&gt;$$
i\hbar\frac{\partial \psi}{\partial t}
  = \frac{-\hbar^2}{2m} \frac{\partial^2 \psi}{\partial x^2} + V \psi
$$&lt;/p&gt;
</summary><category term="matplotlib"></category><category term="animation"></category><category term="simulation"></category></entry><entry><title>Numba vs Cython</title><link href="http://jasminjohnson.github.io/blog/2012/08/24/numba-vs-cython/" rel="alternate"></link><published>2012-08-24T10:41:00-04:00</published><updated>2012-08-24T10:41:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2012-08-24:blog/2012/08/24/numba-vs-cython/</id><summary type="html">

&lt;p&gt;&lt;em&gt;For a more up-to-date comparison of Numba and Cython, see the&lt;/em&gt;
&lt;a href="http://jakevdp.github.io/blog/2013/06/15/numba-vs-cython-take-2/"&gt;&lt;em&gt;newer post&lt;/em&gt;&lt;/a&gt;
&lt;em&gt;on this subject.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Often I'll tell people that I use python for computational analysis, and they
look at me inquisitively.  "Isn't python pretty slow?"  They have a point.
Python is an interpreted language, and as such cannot natively perform
many operations as quickly as a compiled language such as C or Fortran.
There is also the issue of the oft-misunderstood and much-maligned
&lt;a href="http://wiki.python.org/moin/GlobalInterpreterLock"&gt;GIL&lt;/a&gt;,
which calls into question python's ability to allow true parallel computing.&lt;/p&gt;
&lt;p&gt;Many solutions have been proposed: &lt;a href="http://pypy.org/"&gt;PyPy&lt;/a&gt; is a much faster
version of the core python language; 
&lt;a href="http://code.google.com/p/numexpr/"&gt;numexpr&lt;/a&gt; provides optimized performance
on certain classes of operations from within python;
&lt;a href="http://www.scipy.org/Weave/"&gt;weave&lt;/a&gt; allows inline inclusion of compiled
C/C++ code;
&lt;a href="http://www.cython.org/"&gt;cython&lt;/a&gt; provides extra markup that allows python
and/or python-like code to be compiled into C for fast operations.  But
a naysayer might point out: many of these "python" solutions in practice
are not really python at all, but clever hacks into Fortran or C.&lt;/p&gt;
</summary><category term="numba"></category><category term="cython"></category><category term="benchmarks"></category></entry><entry><title>Matplotlib Animation Tutorial</title><link href="http://jasminjohnson.github.io/blog/2012/08/18/matplotlib-animation-tutorial/" rel="alternate"></link><published>2012-08-18T08:01:00-04:00</published><updated>2012-08-18T08:01:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2012-08-18:blog/2012/08/18/matplotlib-animation-tutorial/</id><summary type="html">

&lt;p&gt;&lt;a href="http://matplotlib.sourceforge.net"&gt;Matplotlib&lt;/a&gt; version 1.1 added some tools
for creating
&lt;a href="http://matplotlib.sourceforge.net/api/animation_api.html"&gt;animations&lt;/a&gt;
which are really slick.  You can find some good example animations on
the matplotlib
&lt;a href="http://matplotlib.sourceforge.net/examples/animation/index.html"&gt;examples&lt;/a&gt;
page.  I thought I'd share here some of the things I've learned when playing
around with these tools.&lt;/p&gt;
&lt;h3&gt;Basic Animation&lt;/h3&gt;
&lt;p&gt;The animation tools center around the &lt;code&gt;matplotlib.animation.Animation&lt;/code&gt; base
class, which provides a framework around which the animation functionality
is built.  The main interfaces are &lt;code&gt;TimedAnimation&lt;/code&gt; and &lt;code&gt;FuncAnimation&lt;/code&gt;,
which you can read more about in the
&lt;a href="http://matplotlib.sourceforge.net/api/animation_api.html"&gt;documentation&lt;/a&gt;.
Here I'll explore using the &lt;code&gt;FuncAnimation&lt;/code&gt; tool, which I have found
to be the most useful.&lt;/p&gt;
</summary><category term="matplotlib"></category><category term="animation"></category><category term="tutorial"></category><category term="simulation"></category></entry><entry><title>Memoryview Benchmarks 2</title><link href="http://jasminjohnson.github.io/blog/2012/08/16/memoryview-benchmarks-2/" rel="alternate"></link><published>2012-08-16T14:19:00-04:00</published><updated>2012-08-16T14:19:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2012-08-16:blog/2012/08/16/memoryview-benchmarks-2/</id><summary type="html">

&lt;p&gt;In the &lt;a href="/blog/2012/08/08/memoryview-benchmarks/"&gt;previous post&lt;/a&gt;, I explored
how cython typed memoryviews can be used to speed up repeated array
operations.  It became clear that typed memoryviews are superior to
the ndarray syntax for slicing, and as fast as raw pointers for single
element access.  In the comments, Mathieu brought up an interesting
question: is the ndarray syntax as good as typed memoryviews if you're
not doing slicing?&lt;/p&gt;
&lt;p&gt;The answer turns out to be yes, &lt;em&gt;unless&lt;/em&gt; the compiler tries to inline your
function.&lt;/p&gt;
</summary><category term="numpy"></category><category term="cython"></category><category term="benchmarks"></category><category term="memoryviews"></category></entry><entry><title>Memoryview Benchmarks</title><link href="http://jasminjohnson.github.io/blog/2012/08/08/memoryview-benchmarks/" rel="alternate"></link><published>2012-08-08T18:50:00-04:00</published><updated>2012-08-08T18:50:00-04:00</updated><author><name>Jasmin Johnson</name></author><id>tag:jasminjohnson.github.io,2012-08-08:blog/2012/08/08/memoryview-benchmarks/</id><summary type="html">

&lt;p&gt;There was recently a &lt;a href="https://groups.google.com/forum/?fromgroups#!topic/cython-users/8uuxjB_wbBQ[1-25]" title="cython-users archive"&gt;thread&lt;/a&gt;
on cython-users which caught my eye.  It has to do with 
&lt;a href="http://docs.cython.org/src/userguide/memoryviews.html"&gt;memoryviews&lt;/a&gt;, a new
way of working with memory buffers in cython.&lt;/p&gt;
&lt;p&gt;I've been thinking recently about how to do fast
and flexible memory buffer access in cython.  I contributed the
&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html"&gt;BallTree&lt;/a&gt;
implementation for nearest neighbors searching in
&lt;a href="http://www.scikit-learn.org"&gt;scikit-learn&lt;/a&gt;, and have been actively thinking
about how to make it faster and more flexible, including adding the ability
to specify distance metrics other than euclidean and minkowski.&lt;/p&gt;
&lt;p&gt;In order to accomplish this, I'd like to have a set of distance metric
functions which take two vectors and compute a distance.  There would
be many functions with similar call signatures which could then be
plugged into a code that would iterate over a set of vectors and
compute the appropriate distances.&lt;/p&gt;
</summary><category term="benchmarks"></category><category term="numpy"></category><category term="cython"></category></entry></feed>